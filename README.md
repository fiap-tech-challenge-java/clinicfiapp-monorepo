Absolutamente. Excelente ideia.

Ter um `README.md` claro √© a ferramenta de onboarding mais importante para a equipe, especialmente agora que a funda√ß√£o est√° est√°vel. Isso garante que todos, incluindo os professores, entendam a arquitetura e saibam como executar o projeto em segundos.

Aqui est√° uma proposta de `README.md` para a raiz do projeto. Ele documenta o que fizemos, por que fizemos, e (o mais importante) como rodar.

-----

# ClinicFiapApp - Monorepo (Tech Challenge - Fase 3)

Este reposit√≥rio cont√©m o backend do projeto **ClinicFiapApp**, a solu√ß√£o para o Tech Challenge - Fase 3 do curso de Arquitetura e Desenvolvimento Java.

O objetivo √© desenvolver um sistema hospitalar modular, seguro e ass√≠ncrono, focado em agendamento de consultas, gerenciamento de hist√≥rico de pacientes e envio de notifica√ß√µes.

## üèõÔ∏è Arquitetura

Adotamos uma arquitetura de **Monorepo** gerenciada pelo Maven, contendo m√∫ltiplos microsservi√ßos e bibliotecas compartilhadas. Toda a infraestrutura √© orquestrada via **Docker Compose**.

### M√≥dulos do Projeto

  * `pom.xml` (Raiz): POM Agregador que gerencia todos os m√≥dulos e depend√™ncias.
  * `infra/`: Cont√©m scripts de inicializa√ß√£o da infraestrutura, como a cria√ß√£o autom√°tica dos bancos de dados.
  * `libs/outbox-relay/`: (Futuro) Biblioteca compartilhada para DTOs ou l√≥gicas do padr√£o Outbox.
  * `services/scheduler-service/`: **(Core)** O "c√©rebro" da aplica√ß√£o. Respons√°vel por:
      * Gerenciamento de Usu√°rios (M√©dicos, Pacientes, etc.).
      * Seguran√ßa (Spring Security).
      * L√≥gica de Agendamento de Consultas.
      * API principal (GraphQL).
      * Produ√ß√£o de eventos para o Kafka (usando o Padr√£o Outbox).
  * `services/notification-service/`: Microsservi√ßo consumidor do Kafka, respons√°vel por processar eventos e enviar notifica√ß√µes (ex: lembretes de consulta).
  * `services/history-service/`: Microsservi√ßo consumidor do Kafka que atua como um "Read Model" (CQRS). Ele constr√≥i uma proje√ß√£o de dados otimizada para leitura do hist√≥rico de consultas.

## üõ†Ô∏è Stack Tecnol√≥gica

  * **Java 21**
  * **Spring Boot 3.5.7**
  * **Docker & Docker Compose**
  * **Banco de Dados:** PostgreSQL 17-alpine
  * **Mensageria:** Apache Kafka (Confluent-inc 7.6.1)
  * **API:** Spring for GraphQL
  * **Seguran√ßa:** Spring Security
  * **Migra√ß√£o de BD:** Flyway
  * **Build:** Maven

## üöÄ Como Executar o Projeto (One-Click Run)

Toda a infraestrutura (bancos de dados, Kafka) e os microsservi√ßos s√£o gerenciados pelo Docker Compose.

**Pr√©-requisitos:**

  * Docker e Docker Compose instalados.
  * Portas `5438`, `9092`, `2181`, `8080`, `8081`, `8082`, `8083` livres na sua m√°quina.

### 1\. Executando Tudo com Docker (Recomendado)

Com um √∫nico comando, toda a stack subir√°, incluindo a cria√ß√£o autom√°tica dos bancos de dados e a compila√ß√£o das aplica√ß√µes.

No diret√≥rio raiz do projeto (onde est√° o `docker-compose.yml`), execute:

```bash
docker-compose up -d --build
```

**O que este comando faz:**

1.  **Inicia a Infra:** Sobe os cont√™ineres `postgres`, `zookeeper`, `kafka` e `kafka-ui`.
2.  **Cria os Bancos:** O `postgres` executa o script em `infra/postgres/init/01-init-dbs.sql` e cria automaticamente os bancos `scheduler_db`, `notification_db` e `history_db`.
3.  **Constr√≥i as Aplica√ß√µes:** O Docker usa os `Dockerfiles` de cada servi√ßo (ex: `services/scheduler-service/Dockerfile`) para compilar o c√≥digo Java e gerar as imagens.
4.  **Inicia as Aplica√ß√µes:** Inicia os cont√™ineres `scheduler-service`, `notification-service` e `history-service`.
5.  **Resili√™ncia:** Os servi√ßos Java t√™m `restart: on-failure` para garantir que eles reiniciem caso tentem se conectar ao Postgres antes que este esteja pronto.

### 2\. Para Parar a Execu√ß√£o

```bash
docker-compose down
```

### 3\. Para Resetar (Apagar os Dados dos Bancos)

Se precisar apagar todos os volumes de dados (incluindo o `postgres_data`), use:

```bash
docker-compose down -v
```

### 4\. Desenvolvimento Local (Rodando pela IDE)

Se voc√™ preferir rodar um dos servi√ßos (ex: `scheduler-service`) pela sua IDE para facilitar o debug:

1.  **Inicie apenas a infraestrutura:**

    ```bash
    docker-compose up -d postgres zookeeper kafka kafka-ui
    ```

2.  **Aguarde** a infraestrutura estar pronta (cerca de 15-20 segundos).

3.  **Configure o `application.properties`:** Verifique se o `application.properties` do servi√ßo que voc√™ quer rodar (ex: `services/scheduler-service/src/main/resources/application.properties`) est√° apontando para o `localhost` nas portas corretas:

      * `spring.datasource.url=jdbc:postgresql://localhost:5438/scheduler_db`
      * `spring.kafka.bootstrap-servers=localhost:9092`

4.  **Execute** a classe `main` do servi√ßo (ex: `SchedulerServiceApplication`) pela sua IDE.

## üìç Endere√ßos (Endpoints)

Quando a stack completa est√° de p√© (`docker-compose up`):

| Servi√ßo | Endere√ßo Local | Descri√ß√£o |
| :--- | :--- | :--- |
| **Scheduler Service** | `http://localhost:8081` | Servi√ßo Core (API Principal) |
| ‚Ü≥ GraphQL Playground | `http://localhost:8081/graphiql` | Interface para testar a API GraphQL |
| **Notification Service** | `http://localhost:8082` | Servi√ßo de Notifica√ß√µes |
| **History Service** | `http://localhost:8083` | Servi√ßo de Hist√≥rico (Read Model) |
| ‚Ü≥ GraphQL Playground | `http://localhost:8083/graphiql` | Interface para consultar o hist√≥rico |
| **Kafka UI** | `http://localhost:8080` | UI Web para visualizar t√≥picos do Kafka |
| **PostgreSQL** | `localhost:5438` | Porta do banco para conectar via DBeaver/DataGrip |
| **Kafka** | `localhost:9092` | Porta do broker Kafka para produtores/consumidores locais |

-----
